{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_county_names = [\"Alameda\", \"ContraCosta\", \"Sonoma\", \"Solano\", \"SanMateo\", \"SantaClara\", \"SanFrancisco\", \"Marin\",\"Napa\"] \n",
    "analysis_years = [\"2008\", \"2009\",\"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenates all the census tracts in a given year from all the counties in the Bay Area. This is because when selectiing\n",
    "#neighbors I do not want to eliminate census tracts that border each other but are separated by administrative \n",
    "#boundaries (ie: cities, counties), so I consider the congruous set of tracts for this analysis\n",
    "\n",
    "# I am trying to locate pairs of census tracts that are geographically proximate and demographically similar except\n",
    "# for their CRA eligibility threshold as the first step towards establishing a regression discontinuity design study.\n",
    "# As a preliminary measure, I eliminate census tracts categorized as \"high\" and \"low\" since I want to look for neighboring\n",
    "#tracts that are as close to the CRA threshold as possible in order to compare otherwise similar geographies.\n",
    "for year in analysis_years:\n",
    "    county_files = [f for f in os.listdir(\"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/county_geo_data/\") \n",
    "                    if f[-3:] == \"csv\"\n",
    "                    and f.split('_')[2] == (str(year) +\".csv\")]\n",
    "    countydfs = []\n",
    "    for file in county_files:\n",
    "        df = pd.read_csv(\"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/county_geo_data/\"+file)\n",
    "        countydfs.append(df)\n",
    "    to_write = pd.concat(countydfs, axis=0) #concatenates all the dataframes from that year together\n",
    "    to_write.to_csv(\"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/county_geo_data/\" + \"all_bay_concat_\"+year+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/county_geo_data/'\n",
    "dfs = []\n",
    "for year in analysis_years:\n",
    "    dfs.append(pd.read_csv(path+'all_bay_concat_'+ year+'.csv'))\n",
    "\n",
    "print(dfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in a geodataframe which has the HMDA information geolocated to polygons, concatenated for all of the \n",
    "#9 counties. Builds a dictionary where the keys are each unique tract number and the values are an array of geographic neighbors \n",
    "#of that tract, and the eligibility threshold does not match the tract in question. Currently filters out high and low income\n",
    "#tracts to look at only the center of the distribution, though this might change.\n",
    "\n",
    "\n",
    "\n",
    "def find_neighbors(geodataframe):\n",
    "    neighbors_dict = {}\n",
    "    #geodf_mid_mod = geodataframe[(geodataframe['type'] == \"mod\") | (geodataframe[\"type\"] == \"mid\")]\n",
    "    for df_row in geodataframe.iterrows(): #index, then row\n",
    "        polygon = df_row[1][\"geometry\"]\n",
    "        tract = df_row[1][\"tract\"]\n",
    "        eligibility = df_row[1][\"cra_eligib\"]\n",
    "        neighbors_dict[tract] = list(geodataframe[geodataframe.apply(lambda row: row['geometry'].touches(polygon) and \n",
    "                                        row['cra_eligib'] != eligibility, axis=1)][\"tract\"].values)\n",
    "        #list so that it is easier to write to json later\n",
    "         \n",
    "    return neighbors_dict\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding neighbors for 2008\n",
      "writing 2008 to json\n",
      "finding neighbors for 2009\n",
      "writing 2009 to json\n",
      "finding neighbors for 2010\n",
      "writing 2010 to json\n",
      "finding neighbors for 2011\n",
      "writing 2011 to json\n",
      "finding neighbors for 2012\n",
      "writing 2012 to json\n",
      "finding neighbors for 2013\n",
      "writing 2013 to json\n",
      "finding neighbors for 2014\n",
      "writing 2014 to json\n",
      "finding neighbors for 2015\n",
      "writing 2015 to json\n",
      "finding neighbors for 2016\n",
      "writing 2016 to json\n",
      "finding neighbors for 2017\n",
      "writing 2017 to json\n"
     ]
    }
   ],
   "source": [
    "#neighbors_years = {}\n",
    "for year in analysis_years:\n",
    "    geodf = gp.read_file('/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/combined_shapefiles/all_bay_concat_'+year+'/all_bay_concat_'+year+'.shp')\n",
    "    print(\"finding neighbors for \"+ str(year))\n",
    "    neighbors = find_neighbors(geodf) #save this in json\n",
    "    #neighbors_years[year] = find_neighbors(geodf)\n",
    "\n",
    "    print(\"writing\", str(year), \"to json\")\n",
    "    with open('data/neighbors_'+str(year)+'.json', 'w') as fp:\n",
    "        json.dump(neighbors, fp)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
