{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import shapely\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_county_names = [\"Alameda\", \"ContraCosta\", \"Sonoma\", \"Solano\", \"SanMateo\", \"SantaClara\", \"SanFrancisco\", \"Marin\",\"Napa\"] \n",
    "analysis_years = [\"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"] #try to use 2010 census for this\n",
    "\n",
    "\n",
    "slump_years = [\"2008\", \"2009\", \"2010\", \"2011\", \"2012\"]\n",
    "recovery_years = [\"2013\", \"2014\", \"2015\", \"2016\", \"2017\"]\n",
    "geo_data_path = \"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/county_geo_data/\"\n",
    "parsed_data_path = \"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/parsed_data/\"\n",
    "shapefiles_data_path = \"/Users/ameliabaum/Desktop/Amelia/CRA_Thesis/data/raw_shapefiles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameliabaum/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ameliabaum/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>CENSUSAREA</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400000US06001425103</td>\n",
       "      <td>06</td>\n",
       "      <td>001</td>\n",
       "      <td>425103</td>\n",
       "      <td>4251.03</td>\n",
       "      <td>Tract</td>\n",
       "      <td>0.341</td>\n",
       "      <td>POLYGON ((-122.292355 37.849359, -122.289561 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US06001425104</td>\n",
       "      <td>06</td>\n",
       "      <td>001</td>\n",
       "      <td>425104</td>\n",
       "      <td>4251.04</td>\n",
       "      <td>Tract</td>\n",
       "      <td>0.415</td>\n",
       "      <td>POLYGON ((-122.278597 37.828544, -122.278057 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US06001426100</td>\n",
       "      <td>06</td>\n",
       "      <td>001</td>\n",
       "      <td>426100</td>\n",
       "      <td>4261.00</td>\n",
       "      <td>Tract</td>\n",
       "      <td>1.155</td>\n",
       "      <td>POLYGON ((-122.228079 37.833026, -122.224486 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US06001427100</td>\n",
       "      <td>06</td>\n",
       "      <td>001</td>\n",
       "      <td>427100</td>\n",
       "      <td>4271.00</td>\n",
       "      <td>Tract</td>\n",
       "      <td>0.396</td>\n",
       "      <td>POLYGON ((-122.229935 37.760063, -122.229686 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US06001427800</td>\n",
       "      <td>06</td>\n",
       "      <td>001</td>\n",
       "      <td>427800</td>\n",
       "      <td>4278.00</td>\n",
       "      <td>Tract</td>\n",
       "      <td>0.321</td>\n",
       "      <td>POLYGON ((-122.263533 37.769242, -122.263596 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GEO_ID STATE COUNTY   TRACT     NAME   LSAD  CENSUSAREA  \\\n",
       "0  1400000US06001425103    06    001  425103  4251.03  Tract       0.341   \n",
       "1  1400000US06001425104    06    001  425104  4251.04  Tract       0.415   \n",
       "2  1400000US06001426100    06    001  426100  4261.00  Tract       1.155   \n",
       "3  1400000US06001427100    06    001  427100  4271.00  Tract       0.396   \n",
       "4  1400000US06001427800    06    001  427800  4278.00  Tract       0.321   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-122.292355 37.849359, -122.289561 3...  \n",
       "1  POLYGON ((-122.278597 37.828544, -122.278057 3...  \n",
       "2  POLYGON ((-122.228079 37.833026, -122.224486 3...  \n",
       "3  POLYGON ((-122.229935 37.760063, -122.229686 3...  \n",
       "4  POLYGON ((-122.263533 37.769242, -122.263596 3...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2008 but should be used for all 2000 census geographies (2008-2011)\n",
    "shapefiles_08 = geopandas.read_file(shapefiles_data_path+\"alltracts_shapefiles_2008/tl_2008_06_tract00.shp\")\n",
    "bay_shapefiles_08 = shapefiles_08[shapefiles_08[\"COUNTYFP00\"].isin(['001', '013', '041', '055', '075', '081', '085', '097', '095'])]\n",
    "bay_shapefiles_08[\"NAME00\"] = pd.to_numeric(bay_shapefiles_08[\"NAME00\"])\n",
    "\n",
    "\n",
    "# 2010 and should be used for all HMDA data 2012-2017- I think for right now I'm still using 2000 for these because\n",
    "#it seems like it works the best\n",
    "shapefiles_10 = geopandas.read_file(shapefiles_data_path+\"gz_2010_06_140_00_500k/gz_2010_06_140_00_500k.shp\")\n",
    "bay_shapefiles_10 = shapefiles_10[shapefiles_10[\"COUNTY\"].isin(['001', '013', '041', '055', '075', '081', '085', '097', '095'])]\n",
    "bay_shapefiles_10[\"NAME\"] = pd.to_numeric(bay_shapefiles_10[\"NAME\"])\n",
    "bay_shapefiles_10.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2008\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2008_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2008.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2009\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2009_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2010\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2010_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2010.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2011\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2011_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2011.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2012\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2012_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2012.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2013\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2013_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2014\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2014_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2015\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2015_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2016\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2016_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing... Alameda\n",
      "writing... ContraCosta\n",
      "writing... Sonoma\n",
      "writing... Solano\n",
      "writing... SanMateo\n",
      "writing... SantaClara\n",
      "writing... SanFrancisco\n",
      "writing... Marin\n",
      "writing... Napa\n"
     ]
    }
   ],
   "source": [
    "#2017\n",
    "for county in bay_county_names:\n",
    "    df = pd.read_csv(parsed_data_path+county+\"_2017_parsed.csv\")\n",
    "    with_geo = df.merge(bay_shapefiles_08, how=\"left\", right_on=\"NAME00\", left_on=\"Tract\")  \n",
    "    print(\"writing...\", county)\n",
    "    with_geo.to_csv(geo_data_path+county+\"_geoparsed_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a combined dataframe of all the years in 2 groups, and averages the 4 proportions in this interval.\n",
    "to_concat_recovery = []\n",
    "to_concat_slump = []\n",
    "all_dfs = []\n",
    "files = [f for f in os.listdir(geo_data_path) if f[-3:] == \"csv\"]\n",
    "for name in files:\n",
    "    df_year = name.split('_')[1]\n",
    "    if df_year in slump_years:\n",
    "        df1 = pd.read_csv(geo_data_path+name)\n",
    "        all_dfs.append(df1)\n",
    "        to_concat_slump.append(df1)\n",
    "        \n",
    "    if df_year in recovery_years:\n",
    "        df2 = pd.read_csv(geo_data_path+name)\n",
    "        #print(df2) #include this tract type!\n",
    "        all_dfs.append(df2)\n",
    "        to_concat_recovery.append(df2)\n",
    "#print(to_concat_recovery)\n",
    "#print(to_concat_slump)\n",
    "slump = pd.concat(to_concat_slump, axis=0).drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], \n",
    "                axis=1).groupby(by=[\"Tract\", \"tract num\", \"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"AFFGEOID\", \"GEOID\", \n",
    "                                    \"NAME\", \"LSAD\", \"ALAND\", \"AWATER\", \"geometry\"]).mean()\n",
    "#slump.to_csv(geo_data_path+\"alltracts_recovery.csv\")\n",
    "#print(\"writing... recovery\" )\n",
    "recovery = pd.concat(to_concat_recovery, axis=0).drop([\"Unnamed: 0\", \"Unnamed: 0.1\"],\n",
    "                axis=1).groupby(by=[\"Tract\", \"tract num\", \"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"AFFGEOID\", \"GEOID\", \n",
    "                                    \"NAME\", \"LSAD\", \"ALAND\", \"AWATER\", \"geometry\"]).mean()\n",
    "#recovery.to_csv(geo_data_path+\"alltracts_slump.csv\")\n",
    "#print(\"writing...slump\" )\n",
    "#tract_types = pd.concat(all_dfs, axis=0, )\n",
    "\n",
    "type(all_dfs[0]) #list of dataframes\n",
    "#tract_types\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
